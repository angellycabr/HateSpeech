# -*- coding: utf-8 -*-
"""Extract Model Weights

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QmMc6S0Y56Cok-h1KDTaWGysUB-CPmTy
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from transformers import DistilBertTokenizer, TFDistilBertModel
from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

# Load DistilBERT model & tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')

def encode_texts(texts, tokenizer, max_length=128):
    """ Tokenizes and encodes text for BERT """
    input_ids = []
    attention_masks = []
    for text in texts:
        encoded = tokenizer.encode_plus(text, max_length=max_length, padding='max_length', truncation=True, return_attention_mask=True)
        input_ids.append(encoded['input_ids'])
        attention_masks.append(encoded['attention_mask'])
    return np.array(input_ids), np.array(attention_masks)

def bert_embedding_layer(inputs):
    """Lambda function to use DistilBERT inside Keras model"""
    input_ids, attention_mask = inputs
    return distilbert(input_ids, attention_mask=attention_mask).last_hidden_state

def build_model():
    """Builds the BERT + LSTM model"""
    input_ids = Input(shape=(128,), dtype=tf.int32, name='input_ids')
    attention_mask = Input(shape=(128,), dtype=tf.int32, name='attention_mask')

    # Use a Lambda layer with explicit output shape
    sequence_output = Lambda(bert_embedding_layer, output_shape=(128, 768))([input_ids, attention_mask])

    # LSTM layers
    x = Bidirectional(LSTM(64, return_sequences=True))(sequence_output)
    x = Bidirectional(LSTM(32, return_sequences=False))(x)
    x = Dropout(0.2)(x)
    dense = Dense(32, activation='relu')(x)
    output = Dense(1, activation='sigmoid')(dense)

    model = Model(inputs=[input_ids, attention_mask], outputs=output)
    model.compile(optimizer=Adam(learning_rate=5e-5), loss='binary_crossentropy', metrics=['accuracy'])

    return model

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score

def evaluate_model(model, X_test, y_test, masks):
    """ Evaluate model performance """
    predictions = (model.predict([X_test, masks]) >= 0.5).astype(int)

    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions)
    recall = recall_score(y_test, predictions)
    f1 = f1_score(y_test, predictions)
    mcc = matthews_corrcoef(y_test, predictions)
    auc = roc_auc_score(y_test, predictions)

    return {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "MCC": mcc,
        "AUC": auc
    }

results = {}

import torch
import pandas as pd
from transformers import AutoModel

# Load sarcasm dataset
sarcasm_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/Reddit_balanced.csv')
corpus_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/implicit_hate_v1_stg1_posts.tsv', sep='\t')

# Prepare inputs
sarcasm_comments = sarcasm_df['comment']
sarcasm_parents = sarcasm_df['parent_comment']
sarcasm_labels = sarcasm_df['label']

train_comments, test_comments, train_parents, test_parents, train_labels, test_labels = train_test_split(
    sarcasm_comments, sarcasm_parents, sarcasm_labels, test_size=0.2, random_state=42
)

# Encode text
train_comment_ids, train_comment_masks = encode_texts(train_comments, tokenizer)
test_comment_ids, test_comment_masks = encode_texts(test_comments, tokenizer)
train_parent_ids, _ = encode_texts(train_parents, tokenizer)
test_parent_ids, _ = encode_texts(test_parents, tokenizer)

# Build sarcasm model
sarcasm_model = build_model()
sarcasm_model.load_weights("Sarcasm_model_BERT_vs.weights.h5")

sarcasm_model.summary()

from tensorflow.keras.models import Model

intermediate_layer_model = Model(
    inputs=sarcasm_model.input,
    outputs=sarcasm_model.get_layer('dense_4').output
)

embeddings = intermediate_layer_model.predict([train_comment_ids, train_parent_ids])
pd.DataFrame(embeddings).to_csv('sarcasm_embeddings.csv', index=False)

ethos_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/Ethos_Dataset_Binary.csv', sep=';')
ethos_df['label'] = ethos_df['isHate'].apply(lambda x: 1 if x >= 0.33 else 0)

ethos_comments = ethos_df['comment']
ethos_labels = ethos_df['label']

ethos_train_comments, ethos_test_comments, ethos_train_labels, ethos_test_labels = train_test_split(
    ethos_comments, ethos_labels, test_size=0.6, random_state=42
)

ethos_train_comment_ids, ethos_train_comment_masks = encode_texts(train_comments, tokenizer)
ethos_test_comment_ids, ethos_test_comment_masks = encode_texts(test_comments, tokenizer)

ethos_model = build_model()
ethos_model.load_weights("corpus_model.weights.h5")

ethos_model.summary()

from tensorflow.keras.models import Model

intermediate_layer_model = Model(
    inputs=ethos_model.input,
    outputs=ethos_model.get_layer('dense_6').output
)

ethos_embeddings = intermediate_layer_model.predict([ethos_train_comment_ids, ethos_train_comment_masks])
pd.DataFrame(ethos_embeddings).to_csv('ethos_embeddings.csv', index=False)