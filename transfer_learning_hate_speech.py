# -*- coding: utf-8 -*-
"""Transfer_Learning_Hate_Speech

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l5CJMINRhdJN71xlNugKiOuSZy4AQhBf

Load Libraries & Define Functions
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from transformers import DistilBertTokenizer, TFDistilBertModel
from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

# Load DistilBERT model & tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')

def encode_texts(texts, tokenizer, max_length=128):
    """ Tokenizes and encodes text for BERT """
    input_ids = []
    attention_masks = []
    for text in texts:
        encoded = tokenizer.encode_plus(text, max_length=max_length, padding='max_length', truncation=True, return_attention_mask=True)
        input_ids.append(encoded['input_ids'])
        attention_masks.append(encoded['attention_mask'])
    return np.array(input_ids), np.array(attention_masks)

"""Define Model Architecture"""

def bert_embedding_layer(inputs):
    """Lambda function to use DistilBERT inside Keras model"""
    input_ids, attention_mask = inputs
    return distilbert(input_ids, attention_mask=attention_mask).last_hidden_state

def build_model():
    """Builds the BERT + LSTM model"""
    input_ids = Input(shape=(128,), dtype=tf.int32, name='input_ids')
    attention_mask = Input(shape=(128,), dtype=tf.int32, name='attention_mask')

    # Use a Lambda layer with explicit output shape
    sequence_output = Lambda(bert_embedding_layer, output_shape=(128, 768))([input_ids, attention_mask])

    # LSTM layers
    x = Bidirectional(LSTM(64, return_sequences=True))(sequence_output)
    x = Bidirectional(LSTM(32, return_sequences=False))(x)
    x = Dropout(0.2)(x)
    dense = Dense(32, activation='relu')(x)
    output = Dense(1, activation='sigmoid')(dense)

    model = Model(inputs=[input_ids, attention_mask], outputs=output)
    model.compile(optimizer=Adam(learning_rate=5e-5), loss='binary_crossentropy', metrics=['accuracy'])

    return model

"""Track Performance"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score

def evaluate_model(model, X_test, y_test, masks):
    """ Evaluate model performance """
    predictions = (model.predict([X_test, masks]) >= 0.5).astype(int)

    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions)
    recall = recall_score(y_test, predictions)
    f1 = f1_score(y_test, predictions)
    mcc = matthews_corrcoef(y_test, predictions)
    auc = roc_auc_score(y_test, predictions)

    return {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "MCC": mcc,
        "AUC": auc
    }

results = {}

"""Train Sarcasm Model (Multi-Input)"""

# Load sarcasm dataset
sarcasm_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/Reddit_balanced.csv')

# Prepare inputs
sarcasm_comments = sarcasm_df['comment']
sarcasm_parents = sarcasm_df['parent_comment']
sarcasm_labels = sarcasm_df['label']

train_comments, test_comments, train_parents, test_parents, train_labels, test_labels = train_test_split(
    sarcasm_comments, sarcasm_parents, sarcasm_labels, test_size=0.2, random_state=42
)

# Encode text
train_comment_ids, train_comment_masks = encode_texts(train_comments, tokenizer)
test_comment_ids, test_comment_masks = encode_texts(test_comments, tokenizer)
train_parent_ids, _ = encode_texts(train_parents, tokenizer)
test_parent_ids, _ = encode_texts(test_parents, tokenizer)

# Build sarcasm model
sarcasm_model = build_model()

# Train
sarcasm_model.fit([train_comment_ids, train_comment_masks, train_parent_ids], train_labels, epochs=5, batch_size=64)

# Evaluate
results["Sarcasm"] = evaluate_model(sarcasm_model, test_comment_ids, test_labels, test_comment_masks)

# Save weights
sarcasm_model.save_weights("sarcasm_model_weights.h5")

"""Load Implicit Hate Corpus & Fine-Tune Model"""

from sklearn.utils.class_weight import compute_class_weight

# Load Implicit corpus
corpus_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/implicit_hate_v1_stg1_posts.tsv', sep='\t')

# Combine Implicit and Explicit Samples
corpus_df['hate'] = corpus_df['class'].apply(lambda x: 1 if x in ['implicit_hate', 'explicit_hate'] else 0)

# Distinguish implicit samples from the rest
corpus_df['implicit'] = corpus_df['class'].apply(lambda x: 1 if x in ['implicit_hate'] else 0)

# Prepare inputs
corpus_comments = corpus_df['post']
corpus_labels_implicit = corpus_df['implicit']
corpus_labels_hate = corpus_df['hate']

train_comments, test_comments, train_labels_hate, test_labels_hate = train_test_split(
    corpus_comments, corpus_labels_implicit, test_size=0.2, random_state=42
)

train_comment_ids, train_comment_masks = encode_texts(train_comments, tokenizer)
test_comment_ids, test_comment_masks = encode_texts(test_comments, tokenizer)

# Build Corpus model
corpus_model = build_model()

# Load sarcasm-trained weights into Corpus model
corpus_model.load_weights("sarcasm_model_weights.h5", by_name=True, skip_mismatch=True)

# Freeze BERT layers initially
#for layer in distilbert.layers:
#    layer.trainable = False

# Given the dataset is unbalanced, we'll weigh the classes
implicit_hate_labels = np.array(corpus_labels_implicit)

class_weights = compute_class_weight(class_weight="balanced", classes=np.array([0, 1]), y=implicit_hate_labels)
class_weight_dict = {0: class_weights[0], 1: class_weights[1]}
sample_weights = np.array([class_weight_dict[label] for label in train_labels_hate])

# Fine-tune on Corpus
corpus_model.fit([train_comment_ids, train_comment_masks], train_labels_hate, epochs=15, batch_size=64, sample_weight=sample_weights, validation_data=([test_comment_ids, test_comment_masks], test_labels_hate))

# Evaluate
results["Implicit Hate"] = evaluate_model(corpus_model, test_comment_ids, test_labels_hate, test_comment_masks)

# Save weights
corpus_model.save_weights("corpus_model.weights.h5")
#files.download('corpus_model_weights.h5')

"""Load ETHOS Dataset & Fine-Tune Model"""

# Load ETHOS dataset
ethos_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/Ethos_Dataset_Binary.csv', sep=';')
ethos_df['label'] = ethos_df['isHate'].apply(lambda x: 1 if x >= 0.33 else 0)

# Prepare inputs
ethos_comments = ethos_df['comment']
ethos_labels = ethos_df['label']

train_comments, test_comments, train_labels, test_labels = train_test_split(
    ethos_comments, ethos_labels, test_size=0.6, random_state=42
)

train_comment_ids, train_comment_masks = encode_texts(train_comments, tokenizer)
test_comment_ids, test_comment_masks = encode_texts(test_comments, tokenizer)

# Build ETHOS model (without parent comment)
ethos_model = build_model()

# Load sarcasm-trained weights into ETHOS model
ethos_model.load_weights("corpus_model.weights.h5")
#ethos_model.load_weights("offensive_model.weights.h5")

# Freeze BERT layers initially
#for layer in distilbert.layers:
#    layer.trainable = False

# Fine-tune on ETHOS
ethos_model.fit([train_comment_ids, train_comment_masks], train_labels, epochs=20, batch_size=64, validation_data=([test_comment_ids, test_comment_masks], test_labels))

# Evaluate
results["ETHOS"] = evaluate_model(ethos_model, test_comment_ids, test_labels, test_comment_masks)

# Save weights
ethos_model.save_weights("ethos_model.weights.h5")

"""Load Offensive Dataset & Fine-Tune Model"""

# Load ETHOS dataset
offensive_df = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Datasets/offensive_language_balanced.csv')

# Prepare inputs
offensive_comments = offensive_df['tweet']
offensive_labels = offensive_df['hate_speech']

train_comments, test_comments, train_labels, test_labels = train_test_split(
    offensive_comments, offensive_labels, test_size=0.2, random_state=42
)

train_comment_ids, train_comment_masks = encode_texts(train_comments, tokenizer)
test_comment_ids, test_comment_masks = encode_texts(test_comments, tokenizer)

# Build offensive model
offensive_model = build_model()

# Load corpus-trained weights into offensive model
offensive_model.load_weights("corpus_model.weights.h5")

# Freeze BERT layers initially
#for layer in distilbert.layers:
#    layer.trainable = False

# Fine-tune on ETHOS
offensive_model.fit([train_comment_ids, train_comment_masks], train_labels, epochs=15, batch_size=64, validation_data=([test_comment_ids, test_comment_masks], test_labels))

# Evaluate
results["offensive"] = evaluate_model(offensive_model, test_comment_ids, test_labels, test_comment_masks)

# Save weights
offensive_model.save_weights("offensive_model.weights.h5")

"""Display Metrics"""

# Convert results to DataFrame
import pandas as pd
results_df = pd.DataFrame(results).T

# Display final results
print("\nPerformance Metrics After Each Stage:")
print(results_df)

"""Evaluate the Model"""

from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc

# Make predictions
predicted_probs = ethos_model.predict([test_comment_ids, test_comment_masks])
predicted_labels = (predicted_probs >= 0.5).astype(int)

# Calculate metrics
precision = precision_score(test_labels, predicted_labels)
recall = recall_score(test_labels, predicted_labels)
f1 = f1_score(test_labels, predicted_labels)

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-Score: {f1:.2f}")

"""Visualize Results"""

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Load the model weights
#sarcasm_model.load_weights("sarcasm_model_weights.h5", by_name=True, skip_mismatch=True)
ethos_model.load_weights("ethos_model.weights.h5")

# Split the data to extract the text again
#X_train, X_test, y_train, y_test = train_test_split(sarcasm_df['comment'], sarcasm_df['label'], test_size=0.2, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(ethos_df['comment'], ethos_df['label'], test_size=0.6, random_state=42)

# Reset indices
X_test = X_test.reset_index(drop=True)
y_test_indices = y_test.reset_index(drop=True)

# Generate predictions
#predictions = (sarcasm_model.predict([test_comment_ids, test_comment_masks]) >= 0.5).astype(int)
predictions = (ethos_model.predict([test_comment_ids, test_comment_masks]) >= 0.5).astype(int)
predicted_labels_indices = predictions.flatten()

# Identify correct and incorrect predictions
correct_indices = np.where(predicted_labels_indices == y_test_indices.to_numpy())[0]
incorrect_indices = np.where(predicted_labels_indices != y_test_indices.to_numpy())[0]
correct_sarcasm_samples = [X_test[i] for i in correct_indices ]

# Function to generate a word cloud
def generate_wordcloud(text_samples, title):
    if text_samples:  # Ensure there are valid samples
        text = " ".join(text_samples)
        wordcloud = WordCloud(width=800, height=400, background_color="white", colormap="coolwarm").generate(text)

        # Display word cloud
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation="bilinear")
        plt.axis("off")
        plt.title(title, fontsize=14)
        plt.show()
    else:
        print(f"No correctly classified samples found for {title}.")

# Generate and display word clouds
generate_wordcloud(correct_sarcasm_samples, "Word Cloud of Correctly Classified ETHOS Samples")

# Print first 5 correct and incorrect predictions
print("\nFirst 5 Correct Predictions:")
for i in correct_indices[:5]:
    print(f"Sample {i}:")
    print(f"True Label: {y_test_indices.iloc[i]}, Predicted Label: {predicted_labels_indices[i]}")
    print(f"Text: {X_test[i]}")
    print("-" * 50)

print("\nFirst 5 Incorrect Predictions:")
for i in incorrect_indices[:5]:
    print(f"Sample {i}:")
    print(f"True Label: {y_test_indices.iloc[i]}, Predicted Label: {predicted_labels_indices[i]}")
    print(f"Text: {X_test[i]}")
    print("-" * 50)

